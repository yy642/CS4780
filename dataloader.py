import numpy as np
import feature_selection as fs
import feature_vectorize as fv

idx_list = np.array([1035, 1014,  328,  392,   31,    7,  746,  553,  432,  178, 1041,
        200,  438,  507,  694,  560, 1022,  974,  695,  736,  555,  448,
        969, 1073,  829, 1054,  190,  550,  290,  749,  565,  697,  249,
        476,  600,  914,  528,  222,  634,  269,   40,  342,  205,  291,
         57, 1051,  477,  836,  193,  126,  159,  734,  378,   72,  651,
        987,  588,  132,  814,  640,  851,  430,  661,  212,  816,  433,
        854,  861,    9,  322,  105,  875,  426,  504,  828,  676,  194,
        554,  441,  252,  942,  594,  247,  760,  238,  827, 1018,  297,
        268,  408,  118,  436,  921,  456,  437,  847,  175,  832,  217,
        548,  787,   83,  862,  444,  258,  180,  745,  886,  425,  612,
        558,  372,  489,  527, 1026,  573,  961,  668,  930,  857,  963,
        809, 1053,  719,  763,  591,  833,  242,    5,  515,  439,  370,
        820,  498,  996,  281,  895,  818, 1011,  216,  223,  318,  986,
        618,  231,  704,  650,  179,  207,  356,  771,   11,  702,  284,
        266,  977,  948,  172,  295,  602,  240,  877,  196,   29, 1068,
       1042,  449,  451,  718,  453, 1049,  785,  401,  601,  482,  769,
        134,  157,  344,  732,  737,   66,  270,  435,  446,  572,   81,
        495,  316,  419,  264,  566,  523,   97,  283,  277,  229,  777,
        152,   20,  461,  630,  880, 1059,  725,  570, 1000,  280,  797,
        707,  383,  511,  711, 1019,  519,  578,  670,  271,  903,  462,
         98, 1085, 1031,  870, 1033,  755,  115, 1056,  492,  189, 1060,
        261,  976,  627,  712,  653,  879,  586, 1078,  696,  728,  642,
         38,  723,  469,  699,  621,  692,  689,  690,   56, 1058,  679,
        293,  148,  386,  358,  846,  267,  562,  415,  625,  817,  114,
        549,  522,  958,  584,  753,  643,  663,  139, 1034,  733,  556,
       1009,  225,  856,  457,  803,  713,  631,  450,  120,  538,  349,
        282,  336,  414,  350,  978,   33,  480,   65,  417,   46,  638,
        124,  892,  416,  624,  944,  910,  799,  424, 1020,  872,  620,
        611,  391,  990,  394,  971,  369,  421,  102,  617,  289,  490,
        834,  140,  167,  701,  686,  950,  945,  187,  687,  801,  700,
        104,  136,  819,  473,  894,  765, 1079,  665,  761,  478,  273,
        445,  907,  583,  595,  982,  738,  380, 1083,  329,  299,   67,
       1025,  539,  786,  227,  379,  488,  666,  309, 1072, 1050,  775,
        994,  810, 1047,  302,  521,  313, 1080,  762,  933,  219,  359,
        729,  924,  932,  483,  404,  276,  251,  815,  214,  871,  397,
        263, 1075,  743,  186,   74,  772,  464,  901,  826,  317,  237,
        989,  824,  881,  305,  659,  232,  632,  256,   92,   82,  852,
        791,  805,  764,  593,  605,  364,  779, 1076,   99, 1055,  626,
        724,   13,  355,  968,  878,   22,   91,   60,  922,  547,   27,
        161,  898,  883,  992, 1012,  117,  520,  326,  628,  691,   90,
        532,  512,  447,  213,  160,  909,  162, 1082,  768,  580,  984,
        906,   58,  619,   87,  340,  585,  259,  382,  143,  752,  935,
        848,   30, 1048,    0,  721,  485,  956,  466, 1043,  406,  912,
       1061, 1046,  327,  221,  308,  510,  442,  776,  859,  647,  440,
        962,  637, 1066,  873,  121,  385,  953,  294,  557,  174,  839,
        536,  808,  543,  793,  100,    2,  823,  525,  151,  747,  899,
        708,  710,  410,   80,  680,  353,  884,   23,  211,  341,  616,
        904,  988,  940,  569,  272,  228,  241,  206,  337,  599,  127,
        559,  674,   73,  780,  325, 1065,  288,  888,  925,  387,  609,
         21,    8,  973,  876,  636,  465,  739,  418,  568,  842,  792,
        685,   93,  941,  853,  471,  774,  110,  122, 1067,  514, 1070,
        388,  835,  169,  964,  367,  377,  236,  864,  497,  371,  610,
        590,  915,  173,  646, 1077,   61,  623,  795,  784,  837,  493,
        168,  335,  997,  502,  314,  146, 1023,   63,  184,  204,  783,
        203,  869,  474, 1003,  298,  411,  999,  813,  885,  825,  170,
        524,  615,  202,   10,  111,  191,  957,   75,  103,  840,  304,
        735,  882,  993,  101,   95,  479,  530,   34,   42,  192, 1008,
        181,  215,  164,  671,  804,  952,  348,  275,  141,  542,   35,
        911, 1010,   70,  235,   24,  428,  916,  849,  657,  119,  138,
        811,  675,  113,  714,  582,  363,  758,  688,  552,  412,  274,
        384,  535,  185,  794,  413,   52, 1063,  286,  544,  125, 1032,
        402,  678,   15,  577,  443,  149, 1013,  197,  145,  257,  494,
        354,  183,  541,  693,   76,  667,  850,  717,   25,  770,  796,
       1029,  778,  323,  959,  946,  374,  967,  955,  357,  970,  407,
        481,  744,  373, 1017,  998,  773,  648,  455,  576,  484,  868,
         54,  800,  153,  652, 1044,  254,  951,  491,  844,   12,   14,
        188,  144,  244, 1084,  622,  427,  395,  812, 1016,   53,  545,
        597,  606,  939,  981,  307, 1028,  248,  845,   45,  468,   37,
        130,  865, 1062,   79,  310,  564, 1036,  754,  503,  361,  979,
         39,  195,  896,  841,  742,  802,  782,  403,  390,  897,  715,
        486,  720,  759,   96,  662,  923,   77,   84,  822,  561,  230,
        540,  499,  672,  300,  315,  658,  927,  332,  756,  154, 1087,
        496,  155,  209,  463,    4,  156,  889,   17,  574,  347,  943,
        949,  789, 1015,  529,  644, 1064,  703,  751,  698,   48,  147,
        926,   19,  182,  201,  475,   51,  919,  513,  683,  790,  431,
        806,  389,  673,  381,  243,  635,  319,  234,  660,  112,  399,
        913,   32, 1021,  467,  106,  592,  807,  972,  166,  607,  518,
        863,  516,  985,  551,  306,   86,  908,  654,  176, 1006,  781,
        123,  890,  224,  165,  567,  669,  598,  788,  995,  563,  509,
        265,  171,  980, 1007,  296,  129,  831,  928,   88,  596, 1052,
        262,  199,  740,  400,  434, 1004,  900,  860, 1002,  208,  487,
       1001,  727,  613,  681, 1027,  368,   41,  858,  287,  142,  505,
        604,  893,  360,  705,  938,    6,  546,  991,  684,    1,   64,
        750,  133,  918,  830,  965,  954, 1074,  534,  396,  639,  452,
        366,   89,  608,  575,  821,  312,  709,  581,  320,  226,   16,
        633,  531,  285,  131,  210,   94,   78,  343,  891,  250,  917,
        301,  706,  947,  517,  246,  798,  905,  983,  866,  108,  966,
        579, 1071,  398,    3,  311,  220,  365,  393, 1081,  614, 1088,
        331,  177,  334, 1024,  838,  260,  339,  589,  664,  405,   68,
        920,  902,  351,  731,  163,  116,  303,  333,  459,  158,  198,
        645, 1040,  472,  501,  629,  500,  766,  345,  716,  975,  362,
        338,  726,   43,  233,  128,  655,  423,   71,   36,   26,  730,
        874,  420,  460,   50,  929,  748,  677,  537,  218, 1057,   69,
       1030,  292,  470,  682,   49,  150,   62,  887,  757,  245,  855,
         44,  278,  352,  587, 1086,  641,  506,  458,  454, 1069,  656,
        931,  253,  508,   28,  843,  135,  321,   59,   47,   55,  324,
        533,  767,  137,  937,   18,  526,  375, 1039,  346,  255, 1045,
        960,  409,  330,  279,  239,  722, 1037,  936,  741, 1005,  934,
        603,  376,  867,  649,   85,  571, 1038,  109,  429,  107,  422])

def splitdata(split, extractfeatures, feature_value = None, B = 512, eps = 0.1):
    """
    INPUT:
        split = ['val' | 'test']
        other inputs: see feature_selection.py, feature_vectorize.py
    
    OUTPUT:
        (trainSet, valSet, testSet), where trainSet and valSet are lists of tuples and testSet is
        a tensor.
        valSet: validation set, where valSet[i][0] is the features of the i-th fold
                and valSet[i][1] is the label of the i-th fold, non-empty only if 
                'val' is in split
        trainSet: training set, in the same format as valSet(only 1 fold if 'val' is not in split),
                  always returned. When 'val' is not in split, this contains all the data from 
                  train.csv.
        testSet: test set features (N * D tensor), non-empty only if 'test' is in split and 'val'
                 is not in split
    
    """
    #load raw data and do the pre-processing and tokenization
    labels, tokens = fs.loadtweets(extractfeatures, filename="./train.csv")	

    trainSet, valSet, testSet = [], [], np.array([])
    if 'val' not in split:
        if extractfeatures != 'simplehash':
            d1, d2, d3 = fs.find_word_freq(labels, tokens)
            word_list, df_list = fs.select_word(d1, d2, d3, eps)
        else:
            word_list, df_list = [], []
        trainSet.append((fv.loaddata(tokens, extractfeatures, word_list, df_list, feature_value, B, eps), labels))
        if 'test' in split:
            _, testTokens = fs.loadtweets(extractfeatures, filename="./test.csv")
            testSet = fv.loaddata(testTokens, extractfeatures, word_list, df_list, feature_value, B, eps)
        return trainSet, valSet, testSet
    else:
        # cross validation
        N = len(tokens)
        tokens = np.array(tokens)
        #idx_list = np.arange(N)
        #np.random.shuffle(idx_list)
        preValSet = [
            (tokens[idx_list[:N//5]], labels[idx_list[:N//5]]),
            (tokens[idx_list[N//5 : (2 * N)//5]], labels[idx_list[N//5 : (2 * N)//5]]),
            (tokens[idx_list[(2 * N)//5 : (3 * N)//5]], labels[idx_list[(2 * N)//5 : (3 * N)//5]]),
            (tokens[idx_list[(3 * N)//5 : (4 * N)//5]], labels[idx_list[(3 * N)//5 : (4 * N)//5]]),
            (tokens[idx_list[(4 * N)//5:]], labels[idx_list[(4 * N)//5:]])
        ]
        preTrainSet = [
            (tokens[idx_list[N//5:]],labels[idx_list[N//5:]]),
            (np.concatenate((tokens[idx_list[:N//5]], tokens[idx_list[(2 * N)//5:]])), np.concatenate((labels[idx_list[:N//5]], labels[idx_list[(2 * N)//5:]]))),
            (np.concatenate((tokens[idx_list[:(2 * N)//5]], tokens[idx_list[(3 * N)//5:]])), np.concatenate((labels[idx_list[:(2 * N)//5]], labels[idx_list[(3 * N)//5:]]))),
            (np.concatenate((tokens[idx_list[:(3 * N)//5]], tokens[idx_list[(4 * N)//5:]])), np.concatenate((labels[idx_list[:(3 * N)//5]], labels[idx_list[(4 * N)//5:]]))),
            (tokens[idx_list[:(4 * N)//5]], labels[idx_list[:(4 * N)//5]])
        ]

        for i in range(5): 
            if extractfeatures != 'simplehash':
                d1, d2, d3 = fs.find_word_freq(preTrainSet[i][1], preTrainSet[i][0])
                word_list, df_list = fs.select_word(d1, d2, d3, eps)
            else:
                word_list, df_list = [], []
            trainSet.append((fv.loaddata(preTrainSet[i][0], extractfeatures, word_list, df_list, feature_value, B, eps), preTrainSet[i][1]))
            valSet.append((fv.loaddata(preValSet[i][0], extractfeatures, word_list, df_list, feature_value, B, eps), preValSet[i][1]))

        if 'test' in split:
            print("test set not supported in cross validation")

        return trainSet, valSet, testSet
            
        
